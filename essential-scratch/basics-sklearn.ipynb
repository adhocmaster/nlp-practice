{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a314720b-aa5b-491e-8aa2-d39981c66f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78fbb932-cce8-47b2-b18d-142b564ed2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'This is the first first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "    \"This is a document\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d48b66a-63ec-4e27-adc7-7aea0cfc9fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "  (0, 8)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 2)\t2\n",
      "  (0, 1)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 5)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 1)\t1\n",
      "  (4, 8)\t1\n",
      "  (4, 3)\t1\n",
      "  (4, 1)\t1\n",
      "[[0 1 2 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 0 0 0 1]]\n",
      "set()\n",
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out()) # a is ignored\n",
    "print(X) # sparse\n",
    "print(X.toarray()) # dense\n",
    "print(vectorizer.stop_words_) # a is not in stop words\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "369e4700-7992-43ea-81c7-1a035ccba06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and this' 'document is' 'first document' 'first first' 'is document'\n",
      " 'is the' 'is this' 'second document' 'the first' 'the second' 'the third'\n",
      " 'third one' 'this document' 'this is' 'this the']\n",
      "  (0, 13)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 7)\t1\n",
      "  (2, 13)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 11)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 14)\t1\n",
      "  (4, 13)\t1\n",
      "  (4, 4)\t1\n",
      "[[0 0 1 1 0 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 1 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]]\n",
      "set()\n",
      "{'this is': 13, 'is the': 5, 'the first': 8, 'first first': 3, 'first document': 2, 'this document': 12, 'document is': 1, 'the second': 9, 'second document': 7, 'and this': 0, 'the third': 10, 'third one': 11, 'is this': 6, 'this the': 14, 'is document': 4}\n"
     ]
    }
   ],
   "source": [
    "# n-grams\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out()) # a is ignored\n",
    "print(X) # sparse\n",
    "print(X.toarray()) # dense\n",
    "print(vectorizer.stop_words_) # a is not in stop words\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43e95ee-f413-4f18-b4d2-8ac164d87131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document' 'first' 'second' 'third']\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t2\n",
      "  (1, 0)\t2\n",
      "  (1, 2)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (4, 0)\t1\n",
      "[[1 2 0 0]\n",
      " [2 0 1 0]\n",
      " [0 0 0 1]\n",
      " [1 1 0 0]\n",
      " [1 0 0 0]]\n",
      "{'document': 0, 'first': 1, 'second': 2, 'third': 3}\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer with predefined vocabulary\n",
    "# n-grams\n",
    "vectorizer = CountVectorizer(vocabulary=[\"document\", \"first\", \"second\", \"third\"])\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out()) # a is ignored\n",
    "print(X) # sparse\n",
    "print(X.toarray()) # dense\n",
    "# print(vectorizer.stop_words_) # a is not in stop words\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0fa2ad-4d29-4f82-a8bc-ed13947c6760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.29318281 0.83970668 0.24797215 0.         0.\n",
      "  0.29318281 0.         0.24797215]\n",
      " [0.         0.64612571 0.         0.2732445  0.         0.57343426\n",
      "  0.32306286 0.         0.2732445 ]\n",
      " [0.51492278 0.         0.         0.24536346 0.51492278 0.\n",
      "  0.29009851 0.51492278 0.24536346]\n",
      " [0.         0.42712001 0.6116585  0.36125537 0.         0.\n",
      "  0.42712001 0.         0.36125537]\n",
      " [0.         0.64140349 0.         0.54249496 0.         0.\n",
      "  0.         0.         0.54249496]]\n",
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
     ]
    }
   ],
   "source": [
    "# TFidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "# print(vectorizer.get_feature_names_out()) # a is ignored\n",
    "# print(X) # sparse\n",
    "print(X.toarray()) # dense\n",
    "# print(vectorizer.stop_words_) # a is not in stop words\n",
    "print(vectorizer.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "470939b4-c27f-4247-89b1-ebb692f6c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(print(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be11c66-28b6-4df2-9066-de9514b05dad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m vectorizer\u001b[38;5;241m.\u001b[39mvocabulary_:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(k)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for k, v in vectorizer.vocabulary_:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ceef14-074a-4aec-9969-4c93ba74fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO, do csr_matrix manupulation to get top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eabfd2-e7d9-4a9c-9bcd-2ef15e781f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
